name: Create daily dump backup

on:
  # push:
  #   paths:
  #     - 'data-index.csv'
  workflow_dispatch:  # Allows you to run this workflow manually from the Actions tab

env:
  BASE_URL: "https://www.example.com"
  REQUESTS_PER_MINUTE: 20

jobs:
  download-process-daily-html:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      # - name: Download and extract latest pup release
      #   run: |
      #     LATEST_RELEASE=$(curl -s https://api.github.com/repos/ericchiang/pup/releases/latest | grep "tag_name" | cut -d'"' -f4)
      #     wget -qO /tmp/pup.zip https://github.com/ericchiang/pup/releases/download/${LATEST_RELEASE}/pup_${LATEST_RELEASE}_linux_amd64.zip
      #     unzip /tmp/pup.zip
      #     chmod u+x pup

      - name: Process webpages and commit changes
        run: |
          while IFS=, read -r day path
          do
            formatted_date=$(date -d "$day" +"%Y-%m-%d" 2>/dev/null)
            full_url="$BASE_URL$path"

            if [[ -n "$formatted_date" ]]; then

              # there might be a way to do this with a heredoc but I'm not sure what the action syntax would be
              echo "url = \"${full_url}\"" >> /tmp/curl.urls
              echo -e "output = \"/tmp/data/${formatted_date}.html\"\n" >> /tmp/curl.urls

            fi
          done < data-index.csv

          mkdir -p /tmp/data/

          tail -n 120 /tmp/curl.urls > /tmp/test.urls

          # curl --rate "${REQUESTS_PER_MINUTE}/m" -K /tmp/test.urls

          ls -la /tmp/data

      - name: Setup tmate session
        uses: mxschmitt/action-tmate@v3
